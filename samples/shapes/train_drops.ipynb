{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc97bcab",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Train on Shapes Dataset\n",
    "\n",
    "\n",
    "本笔记本展示了如何在您自己的数据集上训练 Mask R-CNN。 为了简单起见，我们使用形状（正方形、三角形和圆形）的合成数据集，以实现快速训练。 不过，您仍然需要 GPU，因为网络主干是 Resnet101，在 CPU 上训练速度太慢。 在 GPU 上，您可以在几分钟内开始获得不错的结果，并在不到一个小时内获得良好的结果。\n",
    "\n",
    "*Shapes* 数据集的代码如下所示。 它即时生成图像，因此不需要下载任何数据。 它可以生成任意大小的图像，因此我们选择较小的图像大小来更快地训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ecb006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file训练权重文件的本地路径\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e84323f",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd48078",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    玩具形状数据集的训练配置。\n",
    "    从基本 Config 类派生并覆盖特定于玩具形状数据集的值。\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"shapes\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    # 在 1 个 GPU 上训练，每个 GPU 上训练 8 个图像。 我们可以在每个 GPU 上放置多个图像，因为图像很小。 批量大小为 8（GPU * 图像/GPU）。\n",
    "    GPU_COUNT = 1\n",
    "#     IMAGES_PER_GPU过大，显存会溢出，可以设置小一点\n",
    "    IMAGES_PER_GPU = 8\n",
    "\n",
    "    # Number of classes (including background)\n",
    "#     数据集的类别数，第一类为bg，3（比如三角，圆，矩形）类，所以1+3\n",
    "    NUM_CLASSES = 1 + 3  # background + 3 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    # 使用小图像进行更快的训练。 设置小边和大边的界限，这决定了图像的形状。\n",
    "#     实际训练中修改为自己图片的尺寸，如：1280*800应改为：IMAGE_MIN_DIM = 800;IMAGE_MAX_DIM = 1280\n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 128\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    # 使用较小的锚点，因为我们的图像和对象很小\n",
    "#     根据自己情况设置anchor大小，如RPN_ANCHOR_SCALES = (8*6, 16*6, 32*6, 64*6, 128*6)\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    # 减少每张图像的训练 ROI，因为图像很小且对象很少。 旨在让 ROI 采样能够选择 33% 的正 ROI。\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 5\n",
    "    \n",
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c770a",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d114cc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \n",
    "    返回要在笔记本中的所有可视化中使用的 Matplotlib Axes 数组。 提供一个中心点来控制图形大小。\n",
    "\n",
    "    更改默认大小属性以控制渲染图像的大小\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581f384c",
   "metadata": {},
   "source": [
    "## 在全局定义一个iter_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b3aff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_num=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9519a8a2",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Create a synthetic dataset创建合成数据集\n",
    "\n",
    "Extend the Dataset class and add a method to load the shapes dataset, `load_shapes()`, and override the following methods:\n",
    "扩展 Dataset 类并添加一个方法来加载形状数据集，`load_shapes()`，并覆盖以下方法：\n",
    "\n",
    "* load_image()\n",
    "* load_mask()\n",
    "* image_reference()\n",
    "\n",
    "重写一个训练类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c22a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropDataset(util.Dataset):\n",
    "    # 得到该图中有多少个实例（液滴？）\n",
    "    def get_obj_index(self, image):\n",
    "        n = np.max(image)\n",
    "        return n\n",
    "    \n",
    "    # 解析labelme中得到的yaml文件，从而得到mask每一层对应的实例标签\n",
    "    def from_yaml_get_class(self, image_id):\n",
    "        info=self.image_info[image_id]\n",
    "        with open(info['yaml_path'])as f:\n",
    "            temp=yaml.load(f.read())\n",
    "            labels=temp['label_names']\n",
    "            del labels[0]\n",
    "        return labels\n",
    "    \n",
    "    # 重新写draw_mask\n",
    "    def draw_mask(self, num_obj, mask, image):\n",
    "        info = self.image_info[image_id]\n",
    "        for index in range(num_obj):\n",
    "            for i in range(info['width']):\n",
    "                for j in range(info['height']):\n",
    "                    at_pixel = image.getpixel((i,j))\n",
    "                    if at_pixel == index + 1:\n",
    "                        mask[j,i,index] = 1\n",
    "        return mask\n",
    "    \n",
    "    # 重新写load_shapes,里面包含自己的自己的类别（我的是box、column、package、fruitg四类)\n",
    "    # 并在self.image_info信息中添加了path、mask_path、yaml_path\n",
    "    def load_shapes(self,count,height,width,img_floder,mask_floder,imglist,dataset_root_path)\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count:number of images to generate.\n",
    "        height,width:the size of the generated images.\n",
    "        \"\"\"\n",
    "        # Add classes\n",
    "        self.add_class(\"shapes\",1,\"box\")\n",
    "        self.add_class(\"shapes\",2,\"column\")\n",
    "        self.add_class(\"shapes\",3,\"package\")\n",
    "        self.add_class(\"shapes\",4,\"fruit\")\n",
    "        for i in range(count):\n",
    "            filestr=imglist[i].split(\".\")[O]\n",
    "            filestr=filestr.split(\"\")[1]\n",
    "            mask_path=mask_floder+\"/\"+ filestr +\".png\"\n",
    "            yaml_path=dataset_root_path+\"total/rgb_\"+filestr+\"_json/info.yaml\"\n",
    "            self.add_image(\"shapes\",image_id=i,path=img_floder + \"/\"+imglist[i],\n",
    "                           width=width,height=height,mask_path=mask_path,yaml_path=yaml_path)\n",
    "    \n",
    "    # 重写load_mask\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
    "        \"\"\"\n",
    "        global iter_num\n",
    "        info = self.image_info[image_id]\n",
    "        count = 1# number of object\n",
    "        img = Image.open(info['mask_path'])\n",
    "        num_obj = self.get_obj_index(img)\n",
    "        mask=np.zeros([info['height'],info['width'],num_obj],dtype=np.uint8)\n",
    "        mask=self.draw_mask(num_obj, mask, img)\n",
    "        occlusion = np.logical_not(mask[:,:,-1]).astype(np.uint8)\n",
    "        for i in range(count-2, -1, -1):\n",
    "            mask[:,:,i]=mask[:,:,i] * occlusion\n",
    "            occlusion=np.logical_and(occlusion, np.logical_not(mask[:,:,i]))\n",
    "        labels=[]\n",
    "        labels=self.from_yaml_get_class(image_id)\n",
    "        labels_form=[]\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i].find(\"box\")!=-1:\n",
    "                # print \"box\"\n",
    "                labels_form.append(\"box\")\n",
    "            elif labels[i].find(\"column\")!=-1:\n",
    "                # print \"column\"\n",
    "                labels_form.append(\"column\")\n",
    "            elif labels[i].find(\"package\")!=-1:\n",
    "                # print \"package\"\n",
    "                labels_form.append(\"package\")\n",
    "            elif labels[i].find(\"fruit\")!=-1:\n",
    "                # print \"fruit\"\n",
    "                labels_form.append(\"fruit\")\n",
    "        class_ids = np.array([self.class_names.index(s) for s in labels_form])\n",
    "        return mask,class_ids.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d639e9",
   "metadata": {},
   "source": [
    "## 代码主体修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e507a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基础设置\n",
    "# dataset_root_path=\"/home/lijing/workspace_lj/fg_dateset/\"\n",
    "dataset_root_path=\"/dateset/\"\n",
    "img_floder = dataset_root_path + \"rgb\"\n",
    "mask_floder = dataset_root_path + \"mask\"\n",
    "#yaml_floder=dataset_root_path\n",
    "imglist = listdir(img_floder)\n",
    "count = len(imglist)\n",
    "width = 1280\n",
    "height = 800\n",
    "\n",
    "# train与val数据集准备\n",
    "# Training dataset\n",
    "dataset_train=DrugDataset()\n",
    "dataset_train.load_shapes(count,800,1280,img_floder,mask_floder,imglist,dataset_root_path)\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = DrugDataset()\n",
    "dataset_val.load_shapes(count,800,1280,img_floder,mask_floder,imglist,dataset_root_path)\n",
    "dataset_val.prepare()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
